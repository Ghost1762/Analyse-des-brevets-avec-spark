{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb429d1b1a10802",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:08:31.188220800Z",
     "start_time": "2024-06-01T04:56:26.563070900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 paires de titres avec une similarité inférieure à 60% :\n",
      "Titre 1 : a method for obtaining data from an image of an object of a user that has a biometric characteristic of the user, Titre 2 : method for verifying the identity of a user by identifying an object within an image that has a biometric characteristic of the user and mobile device for executing the method, Pourcentage de similarité : 59.93031358885017%\n",
      "Titre 1 : dispositif de pulverisation de produits de traitement pour vegetaux, Titre 2 : dispositif pour l'application de micro-ondes en vue du traitement d'un materiau., Pourcentage de similarité : 59.863945578231295%\n",
      "Titre 1 : method and apparatus for packing bunches of flowers into sleeves, Titre 2 : the method and apparatus for determining the number of living cells in a test fluid, Pourcentage de similarité : 59.863945578231295%\n",
      "Titre 1 : composition comprenant du henne et/ou de l'indigo, une huile et un saccharide, et procede de coloration capillaire la mettant en œuvre, Titre 2 : composition a base de poudres de plante(s) indigofere(s) et de beurres, procede de coloration capillaire mettant en oeuvre cette composition, Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : procédé et dispositif de supervision de traitement d'une culture, Titre 2 : procede et dispositif d'assistance aux manoeuvres de garage d'un vehicule, Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : dispositif et procede pour le developement de formulations, Titre 2 : dispositif et procede de traitement des sols par aeration a stockage de dechets, Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : procede et dispositif d'aide a la preconisation de traitement d'une culture, Titre 2 : procédé et installation de traitement d'hygiénisation de boues, Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : dispositif de deshumidification de produits alimentaires tel le miel, Titre 2 : dispositif d'irradiation de rayons solaires pour traitements medicaux, Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : clou d'arpentage et systeme d'identification a distance d'un tel clou, Titre 2 : sonde optique de deminage et procede d'identification d'un materiau., Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : dispositif de lutte et procede de lutte contre des plantes, Titre 2 : dispositif et procede de traitement des sols par aeration a stockage de dechets, Pourcentage de similarité : 59.854014598540154%\n",
      "Titre 1 : structures fibreuses perforees et ses procedes de fabrication, Titre 2 : granulats legers d'origine vegetale et leur procede de fabrication, Pourcentage de similarité : 59.84251968503938%\n",
      "Titre 1 : dispositif de production de denrees vegetales en terre hors sol, Titre 2 : dispositif de detection de piquets dans des cultures en espalier, Pourcentage de similarité : 59.84251968503938%\n",
      "Titre 1 : machine pour la recolte du tabac et autres plantes analogues, Titre 2 : machine de palissage pour la vigne ou autres plantes ou arbrisseaux, Pourcentage de similarité : 59.84251968503938%\n",
      "Titre 1 : dispositif d'irrigation avec detection de niveau de remplissage, Titre 2 : dispositif de detection de piquets dans des cultures en espalier, Pourcentage de similarité : 59.84251968503938%\n",
      "Titre 1 : procédé et dispositif de traitement de végétaux après récolte, Titre 2 : procede et dispositif de torrefaction de matiere ligneuse vegetale, Pourcentage de similarité : 59.84251968503938%\n",
      "Titre 1 : procede et dispositif de mesure de la couleur d'un objet, Titre 2 : dispositif et procede de mesure de hauteur de couvert vegetal, Pourcentage de similarité : 59.82905982905983%\n",
      "Titre 1 : procede et dispositif de mesure de la couleur d'un objet, Titre 2 : procédé et dispositif de traitement de végétaux après récolte, Pourcentage de similarité : 59.82905982905983%\n",
      "Titre 1 : composition cosmetique ou dermatologique et son utilisation, Titre 2 : composition cosmetique comprenant un colorant hydrosoluble, Pourcentage de similarité : 59.82905982905983%\n",
      "Titre 1 : composition cosmetique ou dermatologique et son utilisation, Titre 2 : composition cosmetique comprenant un colorant hydrosoluble, Pourcentage de similarité : 59.82905982905983%\n",
      "Titre 1 : systeme de traitement automatique, notamment de tonte, d'une zone de travail, Titre 2 : systeme de commande d'un engin de travail, Pourcentage de similarité : 59.82905982905983%\n",
      "+-----------+------+--------+----+----+----------+----------+----------+-------+-----------+--------+-----------+-------+-------+---+-------+----------+--------+-----+------+--------------+-----------+---------+-----+-----------+\n",
      "|Agriculture|System|Agricole|Crop|Soil|Fertilizer|Irrigation|Greenhouse|Weather|Temperature|Humidity|Agriculture|Récolte|Culture|Sol|Engrais|Irrigation|Tracteur|Serre|Climat|Ensoleillement|Température|Prévision|Boden|Gewächshaus|\n",
      "+-----------+------+--------+----+----+----------+----------+----------+-------+-----------+--------+-----------+-------+-------+---+-------+----------+--------+-----+------+--------------+-----------+---------+-----+-----------+\n",
      "|5          |118   |36      |14  |5   |1         |8         |1         |1      |6          |1       |5          |7      |36     |19 |1      |8         |2       |11   |1     |1             |3          |1        |1    |1          |\n",
      "+-----------+------+--------+----+----+----------+----------+----------+-------+-----------+--------+-----------+-------+-------+---+-------+----------+--------+-----+------+--------------+-----------+---------+-----+-----------+\n",
      "Distribution par annee :\n",
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|NULL|826  |\n",
      "|1900|1    |\n",
      "|1964|1    |\n",
      "|1969|1    |\n",
      "|1974|1    |\n",
      "|1977|1    |\n",
      "|1978|1    |\n",
      "|1980|3    |\n",
      "|1981|9    |\n",
      "|1982|11   |\n",
      "|1983|13   |\n",
      "|1984|15   |\n",
      "|1985|10   |\n",
      "|1986|8    |\n",
      "|1987|14   |\n",
      "|1988|15   |\n",
      "|1989|18   |\n",
      "|1990|26   |\n",
      "|1991|11   |\n",
      "|1992|10   |\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par pays :\n",
      "+----------------------+-----+\n",
      "|country               |count|\n",
      "+----------------------+-----+\n",
      "|NULL                  |818  |\n",
      "|European Patent Office|655  |\n",
      "|France                |645  |\n",
      "|China                 |493  |\n",
      "|WIPO (PCT)            |300  |\n",
      "|United States         |218  |\n",
      "|Japan                 |93   |\n",
      "|Canada                |69   |\n",
      "|South Korea           |51   |\n",
      "|Russia                |39   |\n",
      "|Belgium               |34   |\n",
      "|Spain                 |23   |\n",
      "|Australia             |23   |\n",
      "|Taiwan                |12   |\n",
      "|Hungary               |12   |\n",
      "|Switzerland           |8    |\n",
      "|Germany               |7    |\n",
      "|Brazil                |7    |\n",
      "|OAPI                  |6    |\n",
      "|Luxembourg            |6    |\n",
      "+----------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par inventeur actuel :\n",
      "+------------------------------------------------------------------------+-----+\n",
      "|assignee                                                                |count|\n",
      "+------------------------------------------------------------------------+-----+\n",
      "|Individual                                                              |327  |\n",
      "|Null                                                                    |227  |\n",
      "|LOreal SA                                                               |107  |\n",
      "|Centre National de la Recherche Scientifique CNRS                       |29   |\n",
      "|Procter and Gamble Co                                                   |26   |\n",
      "|Commissariat a lEnergie Atomique CEA                                    |24   |\n",
      "|Ricoh Co Ltd                                                            |19   |\n",
      "|3M Innovative Properties Co                                             |18   |\n",
      "|Deere and Co                                                            |15   |\n",
      "|Pellenc SAS                                                             |15   |\n",
      "|Robert Bosch GmbH                                                       |14   |\n",
      "|Semiconductor Energy Laboratory Co Ltd                                  |14   |\n",
      "|Thales SA                                                               |13   |\n",
      "|Societe dAssistance Technique pour Produits Nestle SA                   |13   |\n",
      "|BASF SE                                                                 |12   |\n",
      "|Airbus Helicopters SAS                                                  |10   |\n",
      "|Orange SA                                                               |10   |\n",
      "|LAir Liquide SA pour lEtude et lExploitation des Procedes Georges Claude|9    |\n",
      "|University of California                                                |9    |\n",
      "|Institut National de la Recherche Agronomique INRA                      |8    |\n",
      "+------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par langue :\n",
      "+------------------------+-----+\n",
      "|other_language          |count|\n",
      "+------------------------+-----+\n",
      "|English                 |1777 |\n",
      "|NULL                    |818  |\n",
      "|German                  |597  |\n",
      "|French                  |78   |\n",
      "|Hungarian               |12   |\n",
      "|Bao Tran                |4    |\n",
      "|Farrokh F. Radjy        |4    |\n",
      "|David Naylor            |4    |\n",
      "|Stefan Battlogg         |3    |\n",
      "|Oleg Sinyavskiy         |3    |\n",
      "|Pouria Ghods            |3    |\n",
      "|Jasvir Singh Gill       |3    |\n",
      "|Dean Paul Forgeron      |2    |\n",
      "|Sanford Allan Victor    |2    |\n",
      "|Steven M. Hoffberg      |2    |\n",
      "|David H. Parker         |2    |\n",
      "|Michael Beaugavin Markov|2    |\n",
      "|Eugenio Minvielle       |2    |\n",
      "|Maxime Jean Jerome Bilet|2    |\n",
      "|Timothy McCullough      |2    |\n",
      "+------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Longueur moyenne description :\n",
      "+----------------------+\n",
      "|avg_description_length|\n",
      "+----------------------+\n",
      "|52823.44734601192     |\n",
      "+----------------------+\n",
      "\n",
      "Longueur moyenne revendications :\n",
      "+------------------+\n",
      "|avg_claims_length |\n",
      "+------------------+\n",
      "|1430.2012489355664|\n",
      "+------------------+\n",
      "\n",
      "Freq mots descriptions :\n",
      "+-----------+------+\n",
      "|mot        |count |\n",
      "+-----------+------+\n",
      "|may        |102414|\n",
      "|one        |55060 |\n",
      "|peut       |53844 |\n",
      "|data       |35690 |\n",
      "|system     |30611 |\n",
      "|moins      |30595 |\n",
      "|selon      |28760 |\n",
      "|exemple    |27203 |\n",
      "|entre      |26109 |\n",
      "|least      |25569 |\n",
      "|plus       |25066 |\n",
      "|used       |24496 |\n",
      "|dispositif |22397 |\n",
      "|device     |20992 |\n",
      "|surface    |20340 |\n",
      "|invention  |20193 |\n",
      "|sous       |19938 |\n",
      "|composition|19779 |\n",
      "|include    |19217 |\n",
      "|also       |18965 |\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Freq mots revendications :\n",
      "+--------------+-----+\n",
      "|mot           |count|\n",
      "+--------------+-----+\n",
      "|selon         |9347 |\n",
      "|revendications|5484 |\n",
      "|revendication |4014 |\n",
      "|moins         |3584 |\n",
      "|quelconque    |3516 |\n",
      "|said          |2114 |\n",
      "|der           |2060 |\n",
      "|lequel        |1981 |\n",
      "|entre         |1877 |\n",
      "|ladite        |1744 |\n",
      "|comprend      |1661 |\n",
      "|ledit         |1583 |\n",
      "|moyens        |1487 |\n",
      "|comprenant    |1452 |\n",
      "|Dispositif    |1443 |\n",
      "|claim         |1436 |\n",
      "|wherein       |1422 |\n",
      "|dispositif    |1312 |\n",
      "|according     |1288 |\n",
      "|one           |1279 |\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par inventeur :\n",
      "+---------------------+--------------+\n",
      "|inventor             |nombre_brevets|\n",
      "+---------------------+--------------+\n",
      "|Marc HAVARD          |1             |\n",
      "|Rémi SAYAG           |1             |\n",
      "|Christopher Todd FORD|1             |\n",
      "|Ulf NORDBECK         |1             |\n",
      "|Mikael Willgert      |1             |\n",
      "|Ralf Becker          |1             |\n",
      "|Tyler D Schleicher   |1             |\n",
      "|David Bouchez        |1             |\n",
      "|Christine Camilleri  |1             |\n",
      "|Hermann-Josef Wilhelm|1             |\n",
      "|Mohamed Rebiai       |1             |\n",
      "|Guillaume CHAMPAIN   |1             |\n",
      "|Jon Friedman         |1             |\n",
      "|Troy M. Swartwood    |1             |\n",
      "|Sébastien Hel        |1             |\n",
      "|Frederic Bataille    |1             |\n",
      "|Sébastien KERVERDO   |1             |\n",
      "|Alfred C. Dadson     |1             |\n",
      "|Julien Mercier       |1             |\n",
      "|Juanshu Shen         |1             |\n",
      "+---------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par date publication :\n",
      "+----------------+-----+\n",
      "|publication_date|count|\n",
      "+----------------+-----+\n",
      "|NULL            |818  |\n",
      "|                |8    |\n",
      "|1900-01-01      |1    |\n",
      "|1964-07-31      |1    |\n",
      "|1969-12-11      |1    |\n",
      "|1974-11-08      |1    |\n",
      "|1977-09-15      |1    |\n",
      "|1978-02-15      |1    |\n",
      "|1980-03-21      |1    |\n",
      "|1980-08-20      |1    |\n",
      "|1980-11-26      |1    |\n",
      "|1981-05-08      |1    |\n",
      "|1981-05-22      |1    |\n",
      "|1981-06-26      |1    |\n",
      "|1981-07-10      |1    |\n",
      "|1981-10-09      |1    |\n",
      "|1981-10-16      |1    |\n",
      "|1981-11-06      |1    |\n",
      "|1981-11-18      |1    |\n",
      "|1981-11-20      |1    |\n",
      "+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par pays et annee :\n",
      "+---------+----+-----+\n",
      "|country  |year|count|\n",
      "+---------+----+-----+\n",
      "|NULL     |NULL|818  |\n",
      "|Australia|2006|2    |\n",
      "|Australia|2007|2    |\n",
      "|Australia|2008|1    |\n",
      "|Australia|2009|4    |\n",
      "|Australia|2013|1    |\n",
      "|Australia|2014|2    |\n",
      "|Australia|2015|3    |\n",
      "|Australia|2017|1    |\n",
      "|Australia|2018|2    |\n",
      "|Australia|2019|2    |\n",
      "|Australia|2020|1    |\n",
      "|Australia|2021|2    |\n",
      "|Austria  |2014|1    |\n",
      "|Belgium  |NULL|8    |\n",
      "|Belgium  |1900|1    |\n",
      "|Belgium  |1964|1    |\n",
      "|Belgium  |1969|1    |\n",
      "|Belgium  |1974|1    |\n",
      "|Belgium  |1978|1    |\n",
      "+---------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Distribution par pays et revendications :\n",
      "+----------------------+-----+\n",
      "|country               |count|\n",
      "+----------------------+-----+\n",
      "|European Patent Office|7217 |\n",
      "|France                |4456 |\n",
      "|Japan                 |1669 |\n",
      "|South Korea           |891  |\n",
      "|WIPO (PCT)            |437  |\n",
      "|Germany               |259  |\n",
      "|Spain                 |155  |\n",
      "|Belgium               |130  |\n",
      "|China                 |73   |\n",
      "|Australia             |66   |\n",
      "|OAPI                  |51   |\n",
      "|Brazil                |27   |\n",
      "|Canada                |24   |\n",
      "|Switzerland           |16   |\n",
      "|Austria               |14   |\n",
      "|Eurasian Patent Office|12   |\n",
      "+----------------------+-----+\n",
      "\n",
      "Les données n'ont pas pu être chargées.\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from pyspark.sql.functions import col, regexp_extract, explode, split, concat_ws, avg, length, desc, year, sum, count\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Fonction pour calculer le pourcentage de similarité entre deux chaînes de caractères\n",
    "def similarite(titre1, titre2):\n",
    "    return SequenceMatcher(None, titre1, titre2).ratio() * 100\n",
    "\n",
    "# Fonction pour calculer la similarité entre tous les titres non vides dans le DataFrame\n",
    "def calculer_similarite_entre_titres(df):\n",
    "    similarites = []\n",
    "    titres_non_vides = df.filter(col(\"title\").isNotNull()).select(\"title\").collect()\n",
    "    for i in range(len(titres_non_vides)):\n",
    "        titre1 = titres_non_vides[i][\"title\"].lower()\n",
    "        for j in range(i + 1, len(titres_non_vides)):\n",
    "            titre2 = titres_non_vides[j][\"title\"].lower()\n",
    "            # Vérifier si les titres ne sont pas vides et que la similarité n'est pas de 100%\n",
    "            if titre1 and titre2 and titre1 != titre2:\n",
    "                pourcentage_similarite = similarite(titre1, titre2)\n",
    "                similarites.append((titre1, titre2, pourcentage_similarite))\n",
    "    return similarites\n",
    "\n",
    "# Initialisation de la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analyse des données MongoDB\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/spark.data\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://localhost:27017/spark.data\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Chargement des données\n",
    "try:\n",
    "    df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df = None\n",
    "\n",
    "if df:\n",
    "    # Vérification de l'existence de la colonne 'title'\n",
    "    if 'title' in df.columns:\n",
    "        # Calculer les similarités entre tous les titres non vides\n",
    "        similarites_titres = calculer_similarite_entre_titres(df)\n",
    "\n",
    "        # Filtrer les similarités pour ne garder que celles qui ont une similarité inférieure à 60%\n",
    "        similarites_sous_60 = [sim for sim in similarites_titres if sim[2] < 60]\n",
    "\n",
    "        # Trier les similarités filtrées par ordre décroissant de similarité\n",
    "        top_similarites_sous_60 = sorted(similarites_sous_60, key=lambda x: x[2], reverse=True)[:100]\n",
    "\n",
    "        # Afficher les 20 meilleures paires de titres avec une similarité inférieure à 60%\n",
    "        print(\"Top 20 paires de titres avec une similarité inférieure à 60% :\")\n",
    "        for titre1, titre2, pourcentage_similarite in top_similarites_sous_60[:20]:\n",
    "            print(f\"Titre 1 : {titre1}, Titre 2 : {titre2}, Pourcentage de similarité : {pourcentage_similarite}%\")\n",
    "\n",
    "    # Définition des mots par langue avec des préfixes uniques\n",
    "    english_words = [\n",
    "        \"english_Agriculture\", \"english_System\", \"english_Agricole\", \"english_Farmer\", \"english_Harvest\", \"english_Crop\", \"english_Soil\",\n",
    "        \"english_Fertilizer\", \"english_Irrigation\", \"english_Pesticide\", \"english_Tractor\", \"english_Greenhouse\",\n",
    "        \"english_Weather\", \"english_Climate\", \"english_Rainfall\", \"english_Drought\", \"english_Flood\",\n",
    "        \"english_Sunshine\", \"english_Temperature\", \"english_Forecast\", \"english_Wind\", \"english_Humidity\"\n",
    "    ]\n",
    "    french_words = [\n",
    "        \"french_Agriculture\", \"french_Agriculteur\", \"french_Récolte\", \"french_Culture\", \"french_Sol\",\n",
    "        \"french_Engrais\", \"french_Irrigation\", \"french_Pesticide\", \"french_Tracteur\", \"french_Serre\",\n",
    "        \"french_Météo\", \"french_Climat\", \"french_Précipitations\", \"french_Sécheresse\", \"french_Inondation\",\n",
    "        \"french_Ensoleillement\", \"french_Température\", \"french_Prévision\", \"french_Vent\", \"french_Humidité\"\n",
    "    ]\n",
    "    german_words = [\n",
    "        \"german_Landwirtschaft\", \"german_Bauer\", \"german_Ernte\", \"german_Anbau\", \"german_Boden\",\n",
    "        \"german_Dünger\", \"german_Bewässerung\", \"german_Pestizid\", \"german_Traktor\", \"german_Gewächshaus\",\n",
    "        \"german_Wetter\", \"german_Klima\", \"german_Niederschlag\", \"german_Dürre\", \"german_Überschwemmung\",\n",
    "        \"german_Sonnenschein\", \"german_Temperatur\", \"german_Vorhersage\", \"german_Wind\", \"german_Luftfeuchtigkeit\"\n",
    "    ]\n",
    "    japanese_words = [\n",
    "        \"japanese_農業\", \"japanese_農家\", \"japanese_収穫\", \"japanese_作物\", \"japanese_土壌\",\n",
    "        \"japanese_肥料\", \"japanese_灌漑\", \"japanese_農薬\", \"japanese_トラクター\", \"japanese_温室\",\n",
    "        \"japanese_天気\", \"japanese_気候\", \"japanese_降水量\", \"japanese_干ばつ\", \"japanese_洪水\",\n",
    "        \"japanese_日照\", \"japanese_温度\", \"japanese_予報\", \"japanese_風\", \"japanese_湿度\"\n",
    "    ]\n",
    "    chinese_words = [\n",
    "        \"chinese_农业\", \"chinese_农民\", \"chinese_收获\", \"chinese_作物\", \"chinese_土壤\",\n",
    "        \"chinese_肥料\", \"chinese_灌溉\", \"chinese_杀虫剂\", \"chinese_拖拉机\", \"chinese_温室\",\n",
    "        \"chinese_天气\", \"chinese_气候\", \"chinese_降雨量\", \"chinese_干旱\", \"chinese_洪水\",\n",
    "        \"chinese_阳光\", \"chinese_温度\", \"chinese_预报\", \"chinese_风\", \"chinese_湿度\"\n",
    "    ]\n",
    "\n",
    "    # Combinaison de toutes les listes de mots\n",
    "    combined_words = english_words + french_words + german_words + japanese_words + chinese_words\n",
    "\n",
    "    # Utilisation de regex pour compter les occurrences des mots dans les titres\n",
    "    for word in combined_words:\n",
    "        regex_pattern = f\"(?i)\\\\b{word.split('_', 1)[1]}\\\\b\"\n",
    "        df = df.withColumn(word, (regexp_extract(col(\"title\"), regex_pattern, 0) != \"\").cast(\"int\"))\n",
    "\n",
    "    # Calcul de la somme des occurrences pour chaque mot\n",
    "    word_counts = df.select([sum(col(word)).alias(word) for word in combined_words])\n",
    "\n",
    "    # Filtrer les colonnes dont la somme est supérieure à zéro\n",
    "    non_zero_word_counts = word_counts.select([col(word) for word in word_counts.columns if word_counts.select(sum(col(word))).first()[0] > 0])\n",
    "\n",
    "    # Renommer les colonnes pour supprimer les préfixes de langue\n",
    "    for word in combined_words:\n",
    "        non_zero_word_counts = non_zero_word_counts.withColumnRenamed(word, word.split('_', 1)[1])\n",
    "\n",
    "    # Affichage des résultats\n",
    "    non_zero_word_counts.show(truncate=False)\n",
    "else:\n",
    "    print(\"La colonne 'title' n'existe pas dans le DataFrame.\")\n",
    "\n",
    "# Analyse des descriptions et des revendications\n",
    "# Combinaison des stopwords en anglais, français et chinois\n",
    "english_stopwords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "french_stopwords = StopWordsRemover.loadDefaultStopWords(\"french\")\n",
    "chinese_stopwords = [\"的\", \"了\", \"在\", \"是\", \"我\", \"有\", \"和\", \"不\", \"就\", \"人\", \"都\", \"一\", \"一个\", \"上\", \"也\", \"很\", \"到\", \"说\", \"要\", \"去\", \"你\", \"会\", \"着\", \"没有\", \"看\", \"好\", \"自己\"]\n",
    "combined_stopwords = list(set(english_stopwords + french_stopwords + chinese_stopwords))\n",
    "\n",
    "# Distribution des brevets par année de publication\n",
    "distribution_par_annee = df.groupBy(year(\"publication_date\").alias(\"year\")).count().orderBy(\"year\")\n",
    "\n",
    "# Distribution des brevets par pays\n",
    "distribution_par_pays = df.groupBy(\"country\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "# Distribution des brevets par inventeur ou titulaire actuel\n",
    "distribution_par_inventeur_actuel = df.select(explode(\"current_assignees\").alias(\"assignee\")).groupBy(\"assignee\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "# Distribution des brevets par langue\n",
    "distribution_par_langue = df.groupBy(\"other_language\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "# Concaténation des descriptions en une seule chaîne de caractères\n",
    "concat_descriptions = df.select(concat_ws(\" \", \"description\").alias(\"concat_description\"))\n",
    "\n",
    "# Tokenisation des descriptions\n",
    "tokenized_descriptions = concat_descriptions.select(split(col(\"concat_description\"), \"\\\\s+\").alias(\"tokens\"))\n",
    "\n",
    "# Suppression des stop words des descriptions\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=combined_stopwords)\n",
    "filtered_descriptions = remover.transform(tokenized_descriptions)\n",
    "\n",
    "# Filtrer les mots pour ne garder que ceux contenant des lettres\n",
    "filtered_descriptions = filtered_descriptions.select(\n",
    "    explode(col(\"filtered_tokens\")).alias(\"mot\")).filter(col(\"mot\").rlike(\"^[a-zA-Z]+$\"))\n",
    "\n",
    "# Concaténation des revendications en une seule chaîne de caractères\n",
    "concat_revendications = df.select(concat_ws(\" \", \"claims\").alias(\"concat_claims\"))\n",
    "\n",
    "# Tokenisation des revendications\n",
    "tokenized_revendications = concat_revendications.select(split(col(\"concat_claims\"), \"\\\\s+\").alias(\"tokens\"))\n",
    "\n",
    "# Suppression des stop words des revendications\n",
    "filtered_revendications = remover.transform(tokenized_revendications)\n",
    "\n",
    "# Filtrer les mots pour ne garder que ceux contenant des lettres\n",
    "filtered_revendications = filtered_revendications.select(\n",
    "    explode(col(\"filtered_tokens\")).alias(\"mot\")).filter(col(\"mot\").rlike(\"^[a-zA-Z]+$\"))\n",
    "\n",
    "# Analyse de la longueur moyenne des descriptions et des revendications\n",
    "longueur_moyenne_description = concat_descriptions.select(avg(length(\"concat_description\")).alias(\"avg_description_length\"))\n",
    "longueur_moyenne_revendications = concat_revendications.select(avg(length(\"concat_claims\")).alias(\"avg_claims_length\"))\n",
    "\n",
    "# Calcul de la fréquence des mots dans les descriptions\n",
    "freq_mots_descriptions = filtered_descriptions.groupBy(\"mot\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "# Calcul de la fréquence des mots dans les revendications\n",
    "freq_mots_revendications = filtered_revendications.groupBy(\"mot\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "# Distribution des brevets par inventeur\n",
    "distribution_par_inventeur = df.select(explode(\"inventors\").alias(\"inventor\")) \\\n",
    "                                .groupBy(\"inventor\").agg(count(\"*\").alias(\"nombre_brevets\")) \\\n",
    "                                .orderBy(col(\"nombre_brevets\").asc())\n",
    "\n",
    "# Distribution des brevets par date de publication\n",
    "distribution_par_date_publication = df.groupBy(\"publication_date\").count().orderBy(\"publication_date\")\n",
    "\n",
    "# Distribution des brevets par pays d'origine et année de publication\n",
    "distribution_par_pays_et_annee = df.groupBy(\"country\", year(\"publication_date\").alias(\"year\")).count().orderBy(\"country\", \"year\")\n",
    "\n",
    "# Explode des revendications pour obtenir une ligne par revendication\n",
    "df_exploded = df.select(\"country\", explode(\"claims\").alias(\"claim\"))\n",
    "\n",
    "# Distribution des brevets par pays et nombre de revendications\n",
    "distribution_par_pays_et_revendications = df_exploded.groupBy(\"country\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "results = {\n",
    "    \"distribution_par_annee\": distribution_par_annee,\n",
    "    \"distribution_par_pays\": distribution_par_pays,\n",
    "    \"distribution_par_inventeur_actuel\": distribution_par_inventeur_actuel,\n",
    "    \"distribution_par_langue\": distribution_par_langue,\n",
    "    \"longueur_moyenne_description\": longueur_moyenne_description,\n",
    "    \"longueur_moyenne_revendications\": longueur_moyenne_revendications,\n",
    "    \"freq_mots_descriptions\": freq_mots_descriptions,\n",
    "    \"freq_mots_revendications\": freq_mots_revendications,\n",
    "    \"distribution_par_inventeur\": distribution_par_inventeur,\n",
    "    \"distribution_par_date_publication\": distribution_par_date_publication,\n",
    "    \"distribution_par_pays_et_annee\": distribution_par_pays_et_annee,\n",
    "    \"distribution_par_pays_et_revendications\": distribution_par_pays_et_revendications\n",
    "}\n",
    "\n",
    "for key, df in results.items():\n",
    "    print(f\"{key.replace('_', ' ').capitalize()} :\")\n",
    "    df.show(truncate=False)\n",
    "else:\n",
    "    print(\"Les données n'ont pas pu être chargées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:08:31.208783100Z",
     "start_time": "2024-06-01T05:08:31.175450600Z"
    }
   },
   "id": "53508d640c8ace4d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+--------------------+-----+\n",
      "|country  |year|inventor            |count|\n",
      "+---------+----+--------------------+-----+\n",
      "|Australia|2006|Thomas Giering      |1    |\n",
      "|Australia|2006|Oliver Martin       |1    |\n",
      "|Australia|2006|Graham Butler       |1    |\n",
      "|Australia|2006|Joachim Voelkening  |1    |\n",
      "|Australia|2006|Michael Hodges      |1    |\n",
      "|Australia|2006|Wolfgang Rauscher   |1    |\n",
      "|Australia|2006|Lysis Cubieres      |1    |\n",
      "|Australia|2006|Gerhard Schwenk     |1    |\n",
      "|Australia|2006|Yannick Mechine     |1    |\n",
      "|Australia|2006|Nicholas John Gudde |1    |\n",
      "|Australia|2007|Joanne J. Fillatti  |1    |\n",
      "|Australia|2007|Toni Voelker        |1    |\n",
      "|Australia|2007|Tim Ulmasov         |1    |\n",
      "|Australia|2007|Neal A. Bringe      |1    |\n",
      "|Australia|2007|Monica Colt         |1    |\n",
      "|Australia|2007|Mircea Dan Bucevschi|1    |\n",
      "|Australia|2007|Mendy Axlerad       |1    |\n",
      "|Australia|2008|Jerold Brickler     |1    |\n",
      "|Australia|2008|Roy Cooley          |1    |\n",
      "|Australia|2008|Mark E. Peters      |1    |\n",
      "+---------+----+--------------------+-----+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, explode, desc\n",
    "\n",
    "# Initialisation de la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Distribution des brevets\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/spark.data\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://localhost:27017/spark.data\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Chargement des données\n",
    "try:\n",
    "    df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df = None\n",
    "\n",
    "if df:\n",
    "    # Filtrage des données pour s'assurer que les colonnes nécessaires ne sont pas nulles\n",
    "    df_filtre = df.filter(col(\"country\").isNotNull() & col(\"publication_date\").isNotNull())\n",
    "\n",
    "    # Distribution des brevets par pays, année de publication et inventeur\n",
    "    distribution_par_pays_annee_inventeur = df_filtre.select(\n",
    "        \"country\",\n",
    "        year(\"publication_date\").alias(\"year\"),\n",
    "        explode(\"inventors\").alias(\"inventor\")\n",
    "    ).groupBy(\"country\", \"year\", \"inventor\").count().orderBy(\"country\", \"year\", desc(\"count\"))\n",
    "\n",
    "    # Affichage des résultats\n",
    "    distribution_par_pays_annee_inventeur.show(truncate=False)\n",
    "else:\n",
    "    print(\"Les données n'ont pas pu être chargées.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:08:34.353853Z",
     "start_time": "2024-06-01T05:08:31.241339600Z"
    }
   },
   "id": "9ce444072fbf0ced"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+----------------------------+-----+\n",
      "|country  |other_language       |inventor                    |count|\n",
      "+---------+---------------------+----------------------------+-----+\n",
      "|Australia|Helen Dacres         |Nam Cao Hoai Le             |1    |\n",
      "|Australia|Helen Dacres         |Yonggang Zhu                |1    |\n",
      "|Australia|Naohiko Hirota       |Naohiko Hirota              |1    |\n",
      "|Australia|Helen Dacres         |Nan Wu                      |1    |\n",
      "|Australia|Dieter H. Klaubert   |James Unch                  |1    |\n",
      "|Australia|Naohiko Hirota       |Hirotaka Kaneda             |1    |\n",
      "|Australia|Dieter H. Klaubert   |Poncho Meisenheimer         |1    |\n",
      "|Australia|Christopher Cooper   |Marshall Medoff             |1    |\n",
      "|Australia|Dignan Herbert Rayner|Ivan Herbert Godfrey RAYNER |1    |\n",
      "|Australia|Stephen Ecob         |Stephen Ecob                |1    |\n",
      "|Australia|Helen Dacres         |Helen Dacres                |1    |\n",
      "|Australia|Naohiko Hirota       |Hisao Kuroda                |1    |\n",
      "|Australia|James M. Brennan     |Christopher Michael Mcginnis|1    |\n",
      "|Australia|James M. Brennan     |James M. Brennan            |1    |\n",
      "|Australia|Taras WANKEWYCZ      |Taras WANKEWYCZ             |1    |\n",
      "|Australia|Stephen Ecob         |Ian Oliver                  |1    |\n",
      "|Australia|James M. Brennan     |Eric Child Wilhelmsen       |1    |\n",
      "|Australia|Lysis Cubieres       |Oliver Martin               |1    |\n",
      "|Australia|Thomas Masterman     |Thomas Masterman            |1    |\n",
      "|Australia|Thomas Masterman     |Robert Paradis              |1    |\n",
      "+---------+---------------------+----------------------------+-----+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc\n",
    "\n",
    "# Distribution des brevets par pays, langue et inventeur\n",
    "distribution_par_pays_langue_inventeur = df_filtre.select(\n",
    "    \"country\",\n",
    "    \"other_language\",\n",
    "    explode(\"inventors\").alias(\"inventor\")\n",
    ").groupBy(\"country\", \"other_language\", \"inventor\").count().orderBy(\"country\", asc(\"count\"))\n",
    "\n",
    "# Affichage des résultats\n",
    "distribution_par_pays_langue_inventeur.show(truncate=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:08:37.009451Z",
     "start_time": "2024-06-01T05:08:34.361876100Z"
    }
   },
   "id": "3508a82613eb0b6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|country  |year|title                                                                                                                                                |count|\n",
      "+---------+----+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|Australia|2006|Portable apparatus for analysis of a refinery feedstock or a product of a refinery process                                                           |1    |\n",
      "|Australia|2006|Value document with luminescent properties                                                                                                           |1    |\n",
      "|Australia|2007|Nucleic acid constructs and methods for producing altered seed oil compositions                                                                      |1    |\n",
      "|Australia|2007|Polymeric materials as stomach filler and their preparation                                                                                          |1    |\n",
      "|Australia|2008|Method and system for calculating and reporting slump in delivery vehicles                                                                           |1    |\n",
      "|Australia|2009|Barley lipoxygenase-1 gene, selection method for barley, materials for malt alcoholic beverages and method for production of malt alcoholic beverages|1    |\n",
      "|Australia|2009|Method for the Validatable Inactivation of Pathogens in Biological Fluid by Irradiation                                                              |1    |\n",
      "|Australia|2009|Dual affinity polypeptides for purification                                                                                                          |1    |\n",
      "|Australia|2009|Method and device for determining a pressure parameter of a plant sample                                                                             |1    |\n",
      "|Australia|2013|Novel coelenterazine substrates and methods of use                                                                                                   |1    |\n",
      "|Australia|2014|Plant profile watering system                                                                                                                        |1    |\n",
      "|Australia|2014|Method and system for positioning an apparatus for monitoring a parabolic reflector aerially                                                         |1    |\n",
      "|Australia|2015|Methods and systems for detecting an analyte or classifying a sample                                                                                 |1    |\n",
      "|Australia|2015|Upgrading process streams                                                                                                                            |1    |\n",
      "|Australia|2015|Processing Biomass                                                                                                                                   |1    |\n",
      "|Australia|2017|An apparatus and system for providing a secondary power source for an electric vehicle                                                               |1    |\n",
      "|Australia|2018|Processing Hydroxy-Carboxylic Acids To Polymers                                                                                                      |1    |\n",
      "|Australia|2018|Methods for the preparation of obeticholic acid and derivatives thereof                                                                              |1    |\n",
      "|Australia|2019|Devices and methods for nucleic acid extraction                                                                                                      |1    |\n",
      "|Australia|2019|System for removal of toxic waste from woody materials                                                                                               |1    |\n",
      "+---------+----+-----------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "# Filtrer les lignes avec des valeurs non nulles dans les colonnes \"country\" et \"publication_date\"\n",
    "df_filtre = df.filter(col(\"country\").isNotNull() & col(\"publication_date\").isNotNull())\n",
    "\n",
    "# Distribution des brevets par pays, année de publication et titre\n",
    "distribution_par_pays_annee_titre = df_filtre.select(\n",
    "    \"country\",\n",
    "    year(\"publication_date\").alias(\"year\"),\n",
    "    \"title\"\n",
    ").groupBy(\"country\", \"year\", \"title\").count().orderBy(\"country\", \"year\", desc(\"count\"))\n",
    "\n",
    "# Affichage des résultats\n",
    "distribution_par_pays_annee_titre.show(truncate=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:08:37.798321100Z",
     "start_time": "2024-06-01T05:08:36.124836500Z"
    }
   },
   "id": "47edee18386637a0"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing DataFrame: Distribution_par_annee\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_annee: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_pays\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_pays: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_inventeur\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_inventeur: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_langue\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_langue: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Longueur_moyenne_description\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Longueur_moyenne_description: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Longueur_moyenne_revendications\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Longueur_moyenne_revendications: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Freq_mots_descriptions\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Freq_mots_descriptions: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Freq_mots_revendications\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Freq_mots_revendications: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_pays_et_annee\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_pays_et_annee: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_pays_et_revendications\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_pays_et_revendications: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_pays_annee_inventeur\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_pays_annee_inventeur: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_pays_langue_inventeur\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_pays_langue_inventeur: 'Engine' object has no attribute 'cursor'\n",
      "INFO:root:Processing DataFrame: Distribution_par_pays_annee_titre\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6572\\110751417.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
      "ERROR:root:Error inserting DataFrame Distribution_par_pays_annee_titre: 'Engine' object has no attribute 'cursor'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames have been processed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine('postgresql+psycopg2://postgres:12345678@localhost:5432/PostgreSQL_16')\n",
    "\n",
    "# Dictionary containing Spark DataFrames\n",
    "dataframes_spark = {\n",
    "    'Distribution_par_annee': distribution_par_annee,\n",
    "    'Distribution_par_pays': distribution_par_pays,\n",
    "    'Distribution_par_inventeur': distribution_par_inventeur,\n",
    "    'Distribution_par_langue': distribution_par_langue,\n",
    "    'Longueur_moyenne_description': longueur_moyenne_description,\n",
    "    'Longueur_moyenne_revendications': longueur_moyenne_revendications,\n",
    "    'Freq_mots_descriptions': freq_mots_descriptions,\n",
    "    'Freq_mots_revendications': freq_mots_revendications,\n",
    "    'Distribution_par_pays_et_annee': distribution_par_pays_et_annee,\n",
    "    'Distribution_par_pays_et_revendications': distribution_par_pays_et_revendications,\n",
    "    'Distribution_par_pays_annee_inventeur': distribution_par_pays_annee_inventeur,\n",
    "    'Distribution_par_pays_langue_inventeur': distribution_par_pays_langue_inventeur,\n",
    "    'Distribution_par_pays_annee_titre': distribution_par_pays_annee_titre\n",
    "}\n",
    "\n",
    "# Convert Spark DataFrames to pandas DataFrames and insert into PostgreSQL\n",
    "for df_name, df_spark in dataframes_spark.items():\n",
    "    try:\n",
    "        logging.info(f\"Processing DataFrame: {df_name}\")\n",
    "        df_pandas = df_spark.toPandas()\n",
    "        df_pandas.to_sql(df_name, engine, if_exists='replace', index=False)\n",
    "        logging.info(f\"Successfully inserted DataFrame: {df_name}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error inserting DataFrame {df_name}: {e}\")\n",
    "\n",
    "print(\"All DataFrames have been processed.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:40:55.997703900Z",
     "start_time": "2024-06-01T05:40:51.301537900Z"
    }
   },
   "id": "808dacbdf249859d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Connexion à la base de données\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"PostgreSQL_16\",\n",
    "    user=\"postgres\",\n",
    "    password=\"12345678\"\n",
    ")\n",
    "\n",
    "# Création d'un curseur\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Récupération de la liste des tables dans la base de données\n",
    "cur.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\")\n",
    "tables = cur.fetchall()\n",
    "\n",
    "# Parcours de chaque table et export des données\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    # Récupération des données de la table\n",
    "    cur.execute(sql.SQL(\"SELECT * FROM {}\").format(sql.Identifier(table_name)))\n",
    "    data = cur.fetchall()\n",
    "    \n",
    "    # Écriture des données dans le fichier CSV avec l'encodage UTF-8\n",
    "    with open(f\"{table_name}.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "        # Écriture de l'en-tête du fichier CSV avec les noms des colonnes\n",
    "        cur.execute(sql.SQL(\"SELECT column_name FROM information_schema.columns WHERE table_name = %s\"), (table_name,))\n",
    "        columns = [col[0] for col in cur.fetchall()]\n",
    "        f.write(','.join(columns) + '\\n')\n",
    "        \n",
    "        # Écriture des données dans le fichier CSV\n",
    "        for row in data:\n",
    "            # Convertir chaque élément de la ligne en chaîne et le protéger contre les caractères spéciaux\n",
    "            row_str = [str(elem).replace(',', '') if elem is not None else '' for elem in row]\n",
    "            f.write(','.join(row_str) + '\\n')\n",
    "\n",
    "\n",
    "# Fermeture du curseur et de la connexion\n",
    "cur.close()\n",
    "conn.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T13:38:37.723490200Z",
     "start_time": "2024-06-01T13:38:37.185169500Z"
    }
   },
   "id": "5dbbc73cdbba9983"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T05:08:44.306793Z",
     "start_time": "2024-06-01T05:08:44.306793Z"
    }
   },
   "id": "911eb14f460f26eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-01T05:08:44.306793Z"
    }
   },
   "id": "a718356a6fd01ab6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
